{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scrp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhttpx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPError, HTTPTransport\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mswiftshadow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProxyInterface\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscrp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RedditScraper\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscrp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChildrenT3\n\u001b[1;32m     11\u001b[0m exit()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scrp'"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "from httpx import HTTPError, HTTPTransport\n",
    "from swiftshadow.classes import ProxyInterface\n",
    "\n",
    "from scrp.client import RedditScraper\n",
    "from scrp.model import ChildrenT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 17:42:31,322 - swiftshadow [INFO]:Cache Expired\n"
     ]
    }
   ],
   "source": [
    "SEARCH_TERMS = [\n",
    "    \"Asylansøgere\",\n",
    "    \"Flygtninge\",\n",
    "    \"Indvandrere\",\n",
    "    \"Migranter\",\n",
    "    \"Udlændinge\",\n",
    "]\n",
    "\n",
    "PROXY_MANAGER = ProxyInterface(protocol=\"http\", autoRotate=True, autoUpdate=False)\n",
    "await PROXY_MANAGER.async_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scraper():\n",
    "    proxy = PROXY_MANAGER.get()\n",
    "    print(f'Using new proxy \"{proxy.as_string()}\"')\n",
    "\n",
    "    return RedditScraper(\n",
    "        mounts={\n",
    "            f\"{proxy.protocol}://\": HTTPTransport(\n",
    "                proxy=proxy.as_string(),\n",
    "                retries=5,\n",
    "            ),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_fail(attempt: int) -> RedditScraper | None:\n",
    "    if attempt > 5:\n",
    "        return None\n",
    "    sleep(65)\n",
    "    return get_scraper()\n",
    "\n",
    "\n",
    "def search_term(term: str) -> pl.DataFrame:\n",
    "    scraper = get_scraper()\n",
    "\n",
    "    retry_attempts = 0\n",
    "    after, df = None, None\n",
    "\n",
    "    for _ in range(1000):\n",
    "        try:\n",
    "            search = scraper.search(term, limit=100, after=None, show=\"all\")\n",
    "            after = search.data.after\n",
    "        except HTTPError:\n",
    "            scraper = on_fail(retry_attempts)\n",
    "            retry_attempts += 1\n",
    "            if scraper is None:\n",
    "                print(\"still getting errors after 5 retries.\")\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        data = [\n",
    "            children.data\n",
    "            for children in search.data.children\n",
    "            if isinstance(children, ChildrenT3)\n",
    "        ]\n",
    "\n",
    "        if len(data) == 0:\n",
    "            scraper = on_fail(retry_attempts)\n",
    "            retry_attempts += 1\n",
    "            if scraper is None:\n",
    "                print(\"no more data after 5 retries.\")\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        retry_attempts = 0\n",
    "\n",
    "        if df is None:\n",
    "            df = pl.DataFrame(data)\n",
    "        else:\n",
    "            df = df.vstack(pl.DataFrame(data))\n",
    "\n",
    "        print(f\"scraped {len(data)} ({df.height}) rows for term '{term}'.\")\n",
    "\n",
    "        if after is None:\n",
    "            print(\"no more data.\")\n",
    "            break\n",
    "\n",
    "    if df is None:\n",
    "        raise RuntimeError(\"no data was scraped.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new proxy \"http://119.3.113.150:9094\"\n"
     ]
    }
   ],
   "source": [
    "term = SEARCH_TERMS[0]\n",
    "\n",
    "df = search_term(term)\n",
    "df = df.with_columns(search_term=pl.lit(term))\n",
    "\n",
    "path = Path(f\"output/{term}_{df.height}.parquet\".lower())\n",
    "\n",
    "if not path.exists():\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\") as f:\n",
    "        df.write_parquet(path)\n",
    "else:\n",
    "    print(\"failed to write parquet, file already exists.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
